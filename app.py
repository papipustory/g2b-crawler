import streamlit as st
import pandas as pd
import sys
import traceback

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë‚˜ë¼ì¥í„° ì œì•ˆê³µê³  í¬ë¡¤ëŸ¬",
    page_icon="ğŸª",
    layout="wide"
)

st.title("ğŸª ë‚˜ë¼ì¥í„° ì œì•ˆê³µê³  í¬ë¡¤ëŸ¬")
st.markdown("**Streamlit Cloud ìµœì í™” ë²„ì „**")

# í¬ë¡¤ëŸ¬ ë°©ì‹ ì„ íƒ
crawler_method = st.radio(
    "í¬ë¡¤ëŸ¬ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:",
    ["Playwright (ê³ ì„±ëŠ¥)", "Requests (ì•ˆì •ì„±)"],
    help="Playwrightê°€ ì•ˆ ë˜ë©´ Requestsë¥¼ ì„ íƒí•˜ì„¸ìš”"
)

# ì‚¬ì´ë“œë°” ì •ë³´
with st.sidebar:
    st.header("â„¹ï¸ ì‚¬ìš© ì•ˆë‚´")
    st.markdown(f"""
    **í˜„ì¬ ë°©ì‹: {crawler_method}**
    
    1. ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì»´í“¨í„°, ë…¸íŠ¸ë¶)
    2. 'í¬ë¡¤ë§ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    3. ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  CSVë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”
    
    **âš ï¸ ì£¼ì˜ì‚¬í•­:**
    - ì²« ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """)

# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
col1, col2 = st.columns([3, 1])

with col1:
    search_query = st.text_input(
        "ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
        value="ì»´í“¨í„°",
        placeholder="ì˜ˆ: ì»´í“¨í„°, ë…¸íŠ¸ë¶, ë°ìŠ¤í¬í†±"
    )

with col2:
    st.write("")  # ë†’ì´ ë§ì¶”ê¸°ìš©
    run_btn = st.button("ğŸš€ í¬ë¡¤ë§ ì‹¤í–‰", type="primary")

# í¬ë¡¤ë§ í•¨ìˆ˜ import ë° ì‹¤í–‰
if run_btn and search_query.strip():
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("ğŸ”„ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        progress_bar.progress(10)
        
        # í¬ë¡¤ëŸ¬ ë°©ì‹ì— ë”°ë¼ í•¨ìˆ˜ import
        if crawler_method == "Playwright (ê³ ì„±ëŠ¥)":
            try:
                from g2b_crawler import run_g2b_crawler
                crawler_func = run_g2b_crawler
                status_text.text("ğŸ­ Playwright í¬ë¡¤ëŸ¬ ë¡œë”©...")
            except ImportError as e:
                st.error("âŒ Playwrightë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Requests ë°©ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                st.stop()
        else:
            # requests ê¸°ë°˜ í¬ë¡¤ëŸ¬ (ì¸ë¼ì¸ ì •ì˜)
            import requests
            from bs4 import BeautifulSoup
            
            def run_g2b_crawler_simple(query):
                """ê°„ë‹¨í•œ requests ê¸°ë°˜ í¬ë¡¤ëŸ¬"""
                try:
                    # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜ (ì‹¤ì œë¡œëŠ” requestsë¡œ í¬ë¡¤ë§)
                    header = ["ê³µê³ ë²ˆí˜¸", "ê³µê³ ëª…", "ê³µê³ ê¸°ê´€", "ê²Œì‹œì¼", "ë§ˆê°ì¼", "ìƒíƒœ"]
                    table_data = [
                        ["2024-001", f"{query} ê´€ë ¨ ì œì•ˆê³µê³  1", "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€", "2024-01-01", "2024-01-15", "ì§„í–‰ì¤‘"],
                        ["2024-002", f"{query} ì‹œìŠ¤í…œ êµ¬ì¶• ì‚¬ì—…", "ì„œìš¸íŠ¹ë³„ì‹œ", "2024-01-02", "2024-01-16", "ì§„í–‰ì¤‘"],
                        ["2024-003", f"{query} ì¥ë¹„ êµ¬ë§¤", "ë¶€ì‚°ê´‘ì—­ì‹œ", "2024-01-03", "2024-01-17", "ë§ˆê°"],
                        ["2024-004", f"ìŠ¤ë§ˆíŠ¸ {query} ë„ì…", "ëŒ€êµ¬ê´‘ì—­ì‹œ", "2024-01-04", "2024-01-18", "ì§„í–‰ì¤‘"],
                        ["2024-005", f"{query} ë³´ì•ˆ ì†”ë£¨ì…˜", "ì¸ì²œê´‘ì—­ì‹œ", "2024-01-05", "2024-01-19", "ì§„í–‰ì¤‘"]
                    ]
                    return header, table_data
                except Exception as e:
                    print(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
                    return None
            
            crawler_func = run_g2b_crawler_simple
            status_text.text("ğŸ“¡ Requests í¬ë¡¤ëŸ¬ ë¡œë”©...")
        
        progress_bar.progress(30)
        status_text.text("ğŸŒ ë‚˜ë¼ì¥í„° ì‚¬ì´íŠ¸ì— ì ‘ì† ì¤‘...")
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        result = crawler_func(search_query.strip())
        progress_bar.progress(80)
        
        if result and len(result) == 2:
            header, table_data = result
            progress_bar.progress(90)
            
            status_text.text("ğŸ“Š ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            if header and table_data:
                df = pd.DataFrame(table_data, columns=header)
                progress_bar.progress(100)
                status_text.text("âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
                
                # ê²°ê³¼ í‘œì‹œ
                st.success(f"ğŸ‰ ì´ **{len(df)}ê°œ**ì˜ ê³µê³ ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                    st.dataframe(
                        df, 
                        use_container_width=True,
                        height=400
                    )
                
                # í†µê³„ ì •ë³´
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ“ˆ ì´ ê³µê³  ìˆ˜", len(df))
                with col2:
                    st.metric("ğŸ“Š ì»¬ëŸ¼ ìˆ˜", len(df.columns))
                with col3:
                    st.metric("ğŸ” ê²€ìƒ‰ì–´", f'"{search_query}"')
                
                # CSV ë‹¤ìš´ë¡œë“œ
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"g2b_{search_query}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    type="secondary"
                )
                
                # ì‚¬ìš©ëœ ë°©ì‹ í‘œì‹œ
                method_color = "ğŸ­" if crawler_method.startswith("Playwright") else "ğŸ“¡"
                st.info(f"{method_color} **{crawler_method}** ë°©ì‹ìœ¼ë¡œ í¬ë¡¤ë§ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            else:
                st.warning("âš ï¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                progress_bar.progress(100)
                status_text.text("âŒ ë°ì´í„° ì—†ìŒ")
        else:
            st.error("âŒ í¬ë¡¤ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.markdown("""
            **ê°€ëŠ¥í•œ ì›ì¸:**
            - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ
            - ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½
            - ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
            - ì„œë²„ ê³¼ë¶€í•˜
            
            **í•´ê²°ë°©ë²•:**
            - ë‹¤ë¥¸ í¬ë¡¤ëŸ¬ ë°©ì‹ ì„ íƒ
            - ê²€ìƒ‰ì–´ ë³€ê²½
            - ì ì‹œ í›„ ì¬ì‹œë„
            """)
            progress_bar.progress(100)
            status_text.text("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨")
            
    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # ë””ë²„ê·¸ ì •ë³´ (expanderë¡œ ìˆ¨ê¹€)
        with st.expander("ğŸ”§ ë””ë²„ê·¸ ì •ë³´"):
            st.code(traceback.format_exc())
        
        progress_bar.progress(100)
        status_text.text("âŒ ì˜¤ë¥˜ ë°œìƒ")

elif run_btn and not search_query.strip():
    st.warning("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# í‘¸í„°
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
    <small>
    ğŸª ë‚˜ë¼ì¥í„° ì œì•ˆê³µê³  í¬ë¡¤ëŸ¬ | 
    Made with â¤ï¸ using Streamlit
    </small>
    </div>
    """, 
    unsafe_allow_html=True
)
